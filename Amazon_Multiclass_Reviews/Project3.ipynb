{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2CqI0X2_aYg"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "_wXypATEZBd8",
        "outputId": "1851eae9-6524-45cf-f8ee-c1a1f6488a2d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-90fc6fdb4aef>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## This will connect your Google drive with your Colab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    131\u001b[0m   )\n\u001b[1;32m    132\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "## This will connect your Google drive with your Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FoQDmJMCGPo",
        "outputId": "65cc5420-bc8d-46cf-8123-4f8862c8ab1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: vaderSentiment in /usr/local/lib/python3.10/dist-packages (3.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from vaderSentiment) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "!pip install vaderSentiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8HdhAk5JhFL"
      },
      "source": [
        "## Import necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yG5BPvRqJl84"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score, f1_score, accuracy_score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDWaq8sjqil_"
      },
      "source": [
        "## Reading in train and test files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afAc0Le_qtvR",
        "outputId": "a1bb227c-da09-4ebb-cecf-b952e7d35e40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['reviewText', 'id'], dtype='object')\n",
            "                                          reviewText   id\n",
            "0  all of the reviews for this product are fake. ...  ab0\n",
            "1                    wrong part. our fault. One Star  ab1\n",
            "2          this wire set it really sucks!!! One Star  ab2\n",
            "3  first use, it leaked instantly. even at 5 buck...  ab3\n",
            "4                                didn't fit One Star  ab4\n",
            "0        1\n",
            "1        1\n",
            "2        1\n",
            "3        1\n",
            "4        1\n",
            "        ..\n",
            "29184    5\n",
            "29185    5\n",
            "29186    5\n",
            "29187    5\n",
            "29188    5\n",
            "Name: overall, Length: 29189, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# import the data into a dataframe df\n",
        "df = pd.read_csv('/content/drive/Shareddrives/CS74/Project3/amazon_train.csv')\n",
        "\n",
        "test_df = pd.read_csv('/content/drive/Shareddrives/CS74/Project3/amazon_test.csv')\n",
        "\n",
        "excluded_col = ['reviewTime', 'reviewerID', 'summary', 'reviewerName', 'unixReviewTime', 'image', 'style', 'asin', 'vote', 'category', 'verified']\n",
        "text_col = 'reviewText'\n",
        "\n",
        "df['reviewText'] = df['reviewText'] + \" \" + df['summary']\n",
        "test_df['reviewText'] = test_df['reviewText'] + \" \" + test_df['summary']\n",
        "\n",
        "\n",
        "#drop excluded columns\n",
        "df = df.drop(columns=excluded_col)\n",
        "test_df = test_df.drop(columns=excluded_col)\n",
        "\n",
        "#handle NaN values\n",
        "df[text_col].fillna('', inplace=True)\n",
        "test_df[text_col].fillna('', inplace=True)\n",
        "\n",
        "# df['vote'].fillna(0, inplace=True)\n",
        "# test_df['vote'].fillna(0, inplace=True)\n",
        "\n",
        "\n",
        "y_train = df['overall']\n",
        "df = df.drop('overall', axis=1)\n",
        "print(df.columns)\n",
        "print(df.head())\n",
        "print(y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTSlTNeapqkD"
      },
      "source": [
        "## Text preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stQKPAAqpwLK"
      },
      "source": [
        "We use a TFIDF vectorizer to preprocess our text data. This means that we need to separate the review text into individual words, and then have columns in the dataframe for each unique word, with a TFIDF score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NgnjvKc2pp7v"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer(max_features=1500, ngram_range=(1, 2))\n",
        "\n",
        "word_counts = vectorizer.fit_transform(df[text_col].tolist())\n",
        "word_counts_df = pd.DataFrame(word_counts.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "text_df = pd.concat([df, word_counts_df], axis=1)\n",
        "\n",
        "test_word_counts = vectorizer.fit_transform(test_df[text_col].tolist())\n",
        "test_word_counts_df = pd.DataFrame(test_word_counts.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "test_text_df = pd.concat([test_df, test_word_counts_df], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1FF7rObHSHt"
      },
      "source": [
        "## Cleaning up training data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxG6NZfPHZyE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29992633-5bd6-4422-9baa-2d917785492a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    10  100   11   12   15  16   20   30   50  70  ...  you need  you pay  \\\n",
            "0  0.0  0.0  0.0  0.0  0.0   0  0.0  0.0  0.0   0  ...       0.0      0.0   \n",
            "1  0.0  0.0  0.0  0.0  0.0   0  0.0  0.0  0.0   0  ...       0.0      0.0   \n",
            "2  0.0  0.0  0.0  0.0  0.0   0  0.0  0.0  0.0   0  ...       0.0      0.0   \n",
            "3  0.0  0.0  0.0  0.0  0.0   0  0.0  0.0  0.0   0  ...       0.0      0.0   \n",
            "4  0.0  0.0  0.0  0.0  0.0   0  0.0  0.0  0.0   0  ...       0.0      0.0   \n",
            "\n",
            "   you re  you want  you will  young  your  your money  your phone  yourself  \n",
            "0     0.0       0.0       0.0    0.0   0.0         0.0         0.0       0.0  \n",
            "1     0.0       0.0       0.0    0.0   0.0         0.0         0.0       0.0  \n",
            "2     0.0       0.0       0.0    0.0   0.0         0.0         0.0       0.0  \n",
            "3     0.0       0.0       0.0    0.0   0.0         0.0         0.0       0.0  \n",
            "4     0.0       0.0       0.0    0.0   0.0         0.0         0.0       0.0  \n",
            "\n",
            "[5 rows x 3000 columns]     10  100   11   12   15   16   20   30   50   70  ...  you need  you pay  \\\n",
            "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...       0.0        0   \n",
            "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...       0.0        0   \n",
            "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...       0.0        0   \n",
            "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...       0.0        0   \n",
            "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...       0.0        0   \n",
            "\n",
            "   you re  you want  you will  young      your  your money  your phone  \\\n",
            "0     0.0       0.0       0.0    0.0  0.000000         0.0         0.0   \n",
            "1     0.0       0.0       0.0    0.0  0.098706         0.0         0.0   \n",
            "2     0.0       0.0       0.0    0.0  0.000000         0.0         0.0   \n",
            "3     0.0       0.0       0.0    0.0  0.000000         0.0         0.0   \n",
            "4     0.0       0.0       0.0    0.0  0.000000         0.0         0.0   \n",
            "\n",
            "   yourself  \n",
            "0         0  \n",
            "1         0  \n",
            "2         0  \n",
            "3         0  \n",
            "4         0  \n",
            "\n",
            "[5 rows x 3000 columns]\n"
          ]
        }
      ],
      "source": [
        "X_train = text_df.drop(text_col, axis=1)\n",
        "X_train = X_train.drop('id', axis=1)\n",
        "#y_train defined earlier\n",
        "\n",
        "X_test = test_text_df.drop(text_col, axis=1)\n",
        "X_test = X_test.drop('id', axis=1)\n",
        "\n",
        "#merge missing columns\n",
        "\n",
        "all_col = X_test.columns.tolist() + X_train.columns.tolist()\n",
        "X_train = X_train.reindex(columns=all_col, fill_value=0)\n",
        "X_test = X_test.reindex(columns=all_col, fill_value=0)\n",
        "\n",
        "print(X_train.head(), X_test.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjGhD3eRHgEK"
      },
      "source": [
        "## Cross validation of different models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nipVq10MHkpJ"
      },
      "source": [
        "### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this model was used for testing, trains the model in increments of data\n",
        "\n",
        "model1 = LogisticRegression(C=.5, max_iter=900, multi_class='multinomial', warm_start=True, solver='saga')\n",
        "\n",
        "chunk = 15000\n",
        "num_chunks = len(X_train) // chunk\n",
        "for i in range(num_chunks):\n",
        "    start = i * chunk\n",
        "    end = (i + 1) * chunk\n",
        "\n",
        "    X_chunk = X_train[start:end]\n",
        "    y_chunk = y_train[start:end]\n",
        "\n",
        "    # Update the model with the current chunk\n",
        "    model1.fit(X_chunk, y_chunk)\n",
        "predictions = model1.predict(X_test)\n",
        "\n",
        "submission = pd.DataFrame({'pred': predictions, 'id': test_df['id']})\n",
        "\n",
        "submission.to_csv('output.csv', index=False)"
      ],
      "metadata": {
        "id": "20e6NUgrXI8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAuF1J_yHoVF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ec1aadc-ded9-46ea-d9a4-2f386ea31458"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4084 1169  361  164  179]\n",
            " [1493 2815 1056  397  198]\n",
            " [ 526 1121 2891 1037  287]\n",
            " [ 246  433  941 3064 1085]\n",
            " [ 217  210  246  942 4027]] 0.577291909045036 0.5783343040186372\n"
          ]
        }
      ],
      "source": [
        "model1 = LogisticRegression(C=0.5, max_iter=900, multi_class='multinomial', warm_start=True, solver='saga')\n",
        "\n",
        "model1.fit(X_train, y_train)\n",
        "predictions = model1.predict(X_test)\n",
        "\n",
        "submission = pd.DataFrame({'pred': predictions, 'id': test_df['id']})\n",
        "\n",
        "submission.to_csv('/content/drive/Shareddrives/CS74/Project3/output.csv', index=False)\n",
        "\n",
        "\n",
        "predicted1 = cross_val_predict(model1, X_train, y_train, cv=5)\n",
        "# Calculate the confusion matrix\n",
        "conf_matrix = confusion_matrix(y_train, predicted1)\n",
        "\n",
        "# Calculate macro F1 score\n",
        "macro_f1 = f1_score(y_train, predicted1, average='macro')\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_train, predicted1)\n",
        "\n",
        "print(conf_matrix, macro_f1, accuracy)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted1 = cross_val_predict(model1, X_train, y_train, cv=5, method='predict_proba')\n",
        "\n",
        "#  ROC AUC\n",
        "roc_auc = roc_auc_score(y_train, predicted1, multi_class='ovr', average='macro')\n",
        "print(roc_auc)"
      ],
      "metadata": {
        "id": "lbt4BoYvLMR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "param_grid = {\n",
        "    'solver': ['lbfgs', 'liblinear'],\n",
        "    'C': [ .1, 1],\n",
        "    'warm_start': [True, False],\n",
        "    'max_iter': [800],\n",
        "}\n",
        "# param_grid = {\n",
        "#     'solver': ['lbfgs', 'saga', 'liblinear'],\n",
        "#     'C': [.0001, .001, .01, .1, 1, 10],\n",
        "#     'warm_start': [True, False],\n",
        "#     'max_iter': [800],\n",
        "# }\n",
        "grid_search = GridSearchCV(model1, param_grid, cv=5, scoring='accuracy', n_jobs=-1)"
      ],
      "metadata": {
        "id": "ICqbJyyczMK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "ZjAfvhjTzNC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_params = grid_search.best_params_\n",
        "best_model = grid_search.best_estimator_"
      ],
      "metadata": {
        "id": "QyGvsj5xzOhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(best_params)\n",
        "print(\"-----\")\n",
        "print(best_model)"
      ],
      "metadata": {
        "id": "k-RevVBmzQmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ap5FDalGJ318"
      },
      "source": [
        "\n",
        "\n",
        "### Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahVJ-SBMJ-4_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79161a3c-bb8a-4556-ffc6-90e4766d2d9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[3549 1283  476  342  307]\n",
            " [1489 2470 1056  603  341]\n",
            " [ 630 1168 2409 1142  513]\n",
            " [ 337  529  874 2739 1290]\n",
            " [ 296  286  333 1036 3691]] 0.5072961369560705 0.5090273733255678\n"
          ]
        }
      ],
      "source": [
        "model2 = GaussianNB()\n",
        "model2.fit(X_train, y_train)\n",
        "predictions = model2.predict(X_test)\n",
        "\n",
        "submission = pd.DataFrame({'preds': predictions, 'id': test_df['id']})\n",
        "\n",
        "submission.to_csv('/content/drive/Shareddrives/CS74/Project2/output1.csv', index=False)\n",
        "\n",
        "predicted2 = cross_val_predict(model2, X_train, y_train, cv=5)\n",
        "# Calculate the confusion matrix\n",
        "conf_matrix = confusion_matrix(y_train, predicted2)\n",
        "\n",
        "# Calculate macro F1 score\n",
        "macro_f1 = f1_score(y_train, predicted2, average='macro')\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_train, predicted2)\n",
        "\n",
        "print(conf_matrix, macro_f1, accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted2 = cross_val_predict(model2, X_train, y_train, cv=5, method='predict_proba')\n",
        "\n",
        "#  ROC AUC\n",
        "roc_auc = roc_auc_score(y_train, predicted2, multi_class='ovr', average='macro')\n",
        "print(roc_auc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WO1jVIGgW1s2",
        "outputId": "e1d85f5e-4f3a-495a-e5ce-e2ebc159d8f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7828898522145361\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxgMC_15KVGk"
      },
      "source": [
        "### KNearestNeighbors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMJf-dQAaelS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93acae34-b82e-428b-a782-3507e92d2cc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2156  169   72  165 3395]\n",
            " [1230  939  100  209 3481]\n",
            " [1064  206  928  376 3288]\n",
            " [ 866  211  121 1404 3167]\n",
            " [ 748   85   71  375 4363]] 0.31571633758748413 0.33540032203912434\n"
          ]
        }
      ],
      "source": [
        "model3 = KNeighborsClassifier(algorithm='auto', n_neighbors=7, weights='uniform')\n",
        "model3.fit(X_train, y_train)\n",
        "\n",
        "predicted3 = cross_val_predict(model3, X_train, y_train, cv=5)\n",
        "# Calculate the confusion matrix\n",
        "conf_matrix = confusion_matrix(y_train, predicted3)\n",
        "\n",
        "# Calculate macro F1 score\n",
        "macro_f1 = f1_score(y_train, predicted3, average='macro')\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_train, predicted3)\n",
        "\n",
        "print(conf_matrix, macro_f1, accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted3 = cross_val_predict(model3, X_train, y_train, cv=5, method='predict_proba')\n",
        "\n",
        "#  ROC AUC\n",
        "roc_auc = roc_auc_score(y_train, predicted3, multi_class='ovr', average='macro')\n",
        "print(roc_auc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gbitu0CMXDRR",
        "outputId": "2ad52f79-15a5-4129-b5b0-00e6527d4b3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6469053132375018\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "param_grid = {\n",
        "    'n_neighbors': [4, 5, 6, 7],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'algorithm': ['auto', 'kd_tree', 'ball_tree', 'brute']\n",
        "}\n",
        "\n",
        "grid_search2 = GridSearchCV(model3, param_grid, cv=5, scoring='accuracy', n_jobs=-1)"
      ],
      "metadata": {
        "id": "8SRGEjq4fCP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search2.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "0_8x2qq1f8zB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "3741b84e-af83-49d6-f6dc-12b42cf8bc59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, estimator=KNeighborsClassifier(), n_jobs=-1,\n",
              "             param_grid={'algorithm': ['auto', 'kd_tree', 'ball_tree', 'brute'],\n",
              "                         'n_neighbors': [4, 5, 6, 7],\n",
              "                         'weights': ['uniform', 'distance']},\n",
              "             scoring='accuracy')"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=KNeighborsClassifier(), n_jobs=-1,\n",
              "             param_grid={&#x27;algorithm&#x27;: [&#x27;auto&#x27;, &#x27;kd_tree&#x27;, &#x27;ball_tree&#x27;, &#x27;brute&#x27;],\n",
              "                         &#x27;n_neighbors&#x27;: [4, 5, 6, 7],\n",
              "                         &#x27;weights&#x27;: [&#x27;uniform&#x27;, &#x27;distance&#x27;]},\n",
              "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=KNeighborsClassifier(), n_jobs=-1,\n",
              "             param_grid={&#x27;algorithm&#x27;: [&#x27;auto&#x27;, &#x27;kd_tree&#x27;, &#x27;ball_tree&#x27;, &#x27;brute&#x27;],\n",
              "                         &#x27;n_neighbors&#x27;: [4, 5, 6, 7],\n",
              "                         &#x27;weights&#x27;: [&#x27;uniform&#x27;, &#x27;distance&#x27;]},\n",
              "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_params2 = grid_search2.best_params_\n",
        "best_model2 = grid_search2.best_estimator_"
      ],
      "metadata": {
        "id": "x8uAhk5Df314"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(best_params2)\n",
        "print(\"-----\")\n",
        "print(best_model2)"
      ],
      "metadata": {
        "id": "-2pYKsOpgCuA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87b6b68a-f433-4409-fd27-80c08a733fb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'algorithm': 'auto', 'n_neighbors': 7, 'weights': 'uniform'}\n",
            "-----\n",
            "KNeighborsClassifier(n_neighbors=7)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}